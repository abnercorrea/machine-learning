{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.2 - Logistic Regression - TensorFlow.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKuGrJQYsaLpV/zcgvw2Mv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JE2tgXvnOdfx"},"source":["# Logistic Regression\n","\n","let:\n","\n","$Pr(C1|x) = σ(w^T x+w_0)$ \n","\n","and \n","\n","$Pr(C2|x) = 1−σ(w^T x+w_0)$\n","\n","Learn the parameters w and w0 by conditional likelihood maximization. More specifically use Newton’s algorithm\n","derived in class to optimize the parameters. 10 iterations of Newton’s algorithm should be sufficient for\n","convergence. Add a penalty of $0.5λ||w||_2^2$\n","to regularize the weights. Find the optimal hyperparameter λ\n","by 10-fold cross-validation.\n","\n","## TODO\n","- Draw a graph that shows the cross-validation accuracy of logistic regression as λ varies. Report the best λ.\n","- Report the accuracy of logistic regression (with the best λ for regularization) on\n","the test set. Measure the accuracy by counting the average number of correctly labeled images. An image\n","is correctly labeled when the probability of the correct label is greater than 0.5.\n","- Print also the parameters w, w0 found for logistic regression.\n","- Briefly discuss the results:\n","    - Mixture of Gaussians and logistic regression both find a linear separator, but they use different parameterizations and different objectives. Compare the number of parameters in each model and the\n","amount of computation needed to find a solution with each model. Compare the results for each\n","model.\n","    - Mixture of Gaussians and logistic regression find a linear separator where as k-Nearest Neighbours\n","(in assignment 1) finds a non-linear separator. Compare the expressivity of the separators. Discuss\n","under what circumstances each type of separator is expected to perform best. What could explain\n","the results obtained with KNN in comparison to the results obtained with mixtures of Gaussians and\n","linear regression?"]},{"cell_type":"markdown","metadata":{"id":"7RYBuyShseiF"},"source":["# Logistic Regression\n","- HTF: 4.4, 5.6\n","- N the number of data points\n","- p the number of features\n","- y denote the vector of yi values (yi = 1 for class 1 and yi = 0 for class 2)\n","- X the N × (p + 1) matrix of xi values\n","- p_xw the vector of fitted probabilities with ith element p(xi;βold)\n","- R a N×N diagonal matrix of weights with ith diagonal element p(xi;βold)(1− p(xi; βold))"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uwQYU_neyB-r","executionInfo":{"status":"ok","timestamp":1641107438631,"user_tz":180,"elapsed":1039,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"a2c4ae39-8097-4b9b-b31e-ad987e7e6a47"},"source":["! git clone https://github.com/abnercorrea/machine-learning.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'machine-learning'...\n","remote: Enumerating objects: 98, done.\u001b[K\n","remote: Counting objects: 100% (98/98), done.\u001b[K\n","remote: Compressing objects: 100% (64/64), done.\u001b[K\n","remote: Total 98 (delta 37), reused 84 (delta 23), pack-reused 0\u001b[K\n","Unpacking objects: 100% (98/98), done.\n"]}]},{"cell_type":"code","metadata":{"id":"DCu1L8IEyC4c"},"source":["import sys\n","sys.path += ['/content/machine-learning/src']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8gXYlHCmaRs"},"source":["import numpy as np\n","\n","import tensorflow as tf\n","\n","from abnercorrea.numpy.util.data_prep import read_train_data, read_test_data, norm, prepend_col, to_binary_classes\n","from abnercorrea.numpy.util.data_vis import plot_alpha_scores\n","\n","from abnercorrea.tensorflow.util.stat import logistic_sigmoid\n","from abnercorrea.tensorflow.util.data_prep import split_train_validation_tf\n","from abnercorrea.tensorflow.util.tensorflow import tf_while_loop_body\n","\n","# from abnercorrea.tensorflow.linear.logistic_regression import LogisticRegressionClassifierTF"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p_9jHFkc0pBH"},"source":["\n","# Data"]},{"cell_type":"code","metadata":{"id":"R04afLoaNmXc"},"source":["# read data\n","xtrp, ytrp = read_train_data(num_partitions=10)\n","xtr, ytr = np.concatenate(xtrp), np.concatenate(ytrp)\n","xte, yte = read_test_data()\n","\n","# predictors are all standardized to have mean zero and unit norm.\n","xtr, xte = norm(xtr - xtr.mean()), norm(xte - xte.mean())\n","\n","# yi will be used as a scalar\n","ytr, yte = ytr[:, 0], yte[:, 0]\n","\n","# X bar has 1 for the first dimension of X to accommodate for w0\n","xtr_, xte_ = prepend_col(xtr, 1), prepend_col(xte, 1)\n","\n","# y denote the vector of yi values (yi = 1 for class 1 and yi = 0 for class 2)\n","ytrb, classes = to_binary_classes(ytr)\n","yteb, _ = to_binary_classes(yte)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-U_xWt9vrsN","executionInfo":{"status":"ok","timestamp":1641071831400,"user_tz":180,"elapsed":6,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"f8332a84-a02f-47a9-875c-7a7e3855d0de"},"source":["xtr_.shape, xte_.shape, ytrb.shape, yteb.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1000, 65), (110, 65), (1000,), (110,))"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"aRpyjoDNvslJ"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"32fZTcsoiqTk"},"source":["class LogisticRegressionClassifierTF:\n","    def __init__(self, optimizer='Newton-Raphson', max_iter=10, tol=1e-14, learning_rate=1e-2):\n","        assert optimizer in ['Newton-Raphson', 'sgd'], f'Optimizer {optimizer} not supported.'\n","\n","        self.optimizer = optimizer\n","        self.tol = tol\n","        self.max_iter = max_iter\n","        self.learning_rate = learning_rate\n","        self.w, self.alpha, self.alpha_scores = None, None, None\n","\n","    def fit(self, X_, y, alphas=None, folds=10):\n","        params = self.fit_tf(X_, y, alphas, folds, self.max_iter, self.tol, self.learning_rate)\n","        \n","        self.w, self.alpha, self.alpha_scores = params\n","\n","    @tf.function(\n","        input_signature=[\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=(), dtype=tf.int32),\n","            tf.TensorSpec(shape=(), dtype=tf.int32),\n","            tf.TensorSpec(shape=(), dtype=tf.float64),\n","            tf.TensorSpec(shape=(), dtype=tf.float64),\n","        ]\n","    )\n","    def fit_tf(self, X_, y, alphas, folds, max_iter, tol, learning_rate):\n","        \"\"\"\n","        Trains model and finds weights w and hyper-parameter alpha (regularization).\n","\n","        :param y: denotes the vector of yi values (yi = 1 for class 1 and yi = 0 for class 2)\n","        \"\"\"\n","        alphas_size = tf.size(alphas)\n","        scores = tf.TensorArray(tf.float64, size=alphas_size)\n","        scores = scores.unstack(tf.zeros_like(alphas))\n","\n","        for fold in tf.range(folds, dtype=tf.int32):\n","            # splits train and validation sets\n","            xtr, ytr, xvl, yvl = split_train_validation_tf(X_, y, fold, folds)\n","            for i in tf.range(alphas_size):\n","                # fits model using trainig set\n","                w = self.optimize(xtr, ytr, alphas[i], max_iter=max_iter, tol=tol, learning_rate=learning_rate)\n","                # calculates score using validation set\n","                score = self.score_tf(xvl, yvl, w)\n","                # accumulates score of each alpha over all folds\n","                scores = scores.write(i, scores.read(i) + score)\n","\n","        alpha_scores = scores.stack() / folds\n","        alpha = alphas[tf.argmax(alpha_scores)]\n","        # trains with best alpha using all train data\n","        w = self.optimize(X_, y, alpha, max_iter=max_iter, tol=tol, learning_rate=learning_rate)\n","        return w, alpha, alpha_scores\n","\n","    @tf.function(\n","        input_signature=[\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=(), dtype=tf.float64),\n","            tf.TensorSpec(shape=(), dtype=tf.int32),\n","            tf.TensorSpec(shape=(), dtype=tf.float64),\n","            tf.TensorSpec(shape=(), dtype=tf.float64),\n","        ]\n","    )\n","    def optimize(self, X_, y, alpha, max_iter, tol, learning_rate):\n","        \"\"\"\n","        This maximizes a penalized log-likelihood(w)\n","\n","        The penalty used is: -.5 * alpha * w^2 (L2)\n","\n","        We typically do not penalize the intercept term, and standardize the predictors for the penalty to be meaningful.\n","\n","        It seems that w = 0 is a good starting value for the iterative procedure, although convergence is never guaranteed.\n","        Typically the algorithm does converge, since the log-likelihood is concave, but overshooting can occur.\n","        In the rare cases that the log-likelihood decreases, step size halving will guarantee convergence.\n","\n","        This algorithm is referred to as iteratively reweighted least squares or IRLS.\n","\n","        TODO: implement step-size halving in case of not converging\n","        \"\"\"\n","        f = tf.shape(X_)[1]\n","        # w = 0 is a good starting value for the iterative procedure\n","        w0 = tf.zeros(shape=[f], dtype=tf.float64)\n","        # since gradient is used to check convergence, this guarantees at least 1 iteration.\n","        gradient0 = tf.fill(dims=[f], value=tol * 2)\n","\n","        # checks convergence (gradient = 0 which numerically becomes gradient < tol)\n","        def not_converged(wi, gradient):\n","            return tf.reduce_any(tf.abs(gradient) >= tol)\n","\n","        @tf_while_loop_body()\n","        def newton_raphson(wi, gradient):\n","            \"\"\"\n","            From HTF:\n","            The Newton–Raphson algorithm uses the first-derivative or Gradient and the second-derivative or Hessian matrix.\n","\n","            Staring with w_old, the Newton step is:\n","            w_new = w_old - inverse(hessian(log_likelihood(w))) @ gradient(log_likelihood(w))\n","            \"\"\"\n","            gradient, p = self.gradient(X_, y, wi, alpha)\n","            hessian = self.hessian(X_, p, alpha)\n","            hessian_inv = tf.linalg.inv(hessian)\n","            # w_new = w - inverse(hessian(log_likelihood(w))) @ gradient(log_likelihood(w))\n","            wi -= hessian_inv @ gradient\n","            return [wi, gradient]\n","\n","        # TODO: SGD\n","        # @tf_while_loop_body()\n","        # def sgd(wi, gradient):\n","        #     \"\"\"\n","        #     SGD step calculates the gradient to update the value of w.\n","        # \n","        #     Staring with w_old, the Newton step is:\n","        #     w_new = w_old - learning_rate * gradient(log_likelihood(w))\n","        #     \"\"\"\n","        #     gradient, _ = self.gradient(X_, y, wi, alpha)\n","        #     # w_new = w_old - learning_rate * gradient(log_likelihood(w))\n","        #     wi -= learning_rate * gradient\n","        #     return [wi, gradient]\n","\n","        # since back_prop is not needed, using tf.stop_gradient to prevent gradient computation.\n","        [w, _] = tf.nest.map_structure(\n","            tf.stop_gradient,\n","            tf.while_loop(\n","                cond=not_converged,\n","                body=newton_raphson,\n","                loop_vars=[w0, gradient0],\n","                maximum_iterations=max_iter\n","            )\n","        )\n","        return w\n","\n","    def score(self, X_, y):\n","        return self.score_tf(X_, y, self.w)\n","\n","    @tf.function(\n","        input_signature=[\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","        ]\n","    )\n","    def score_tf(self, X_, y, w):\n","        \"\"\"\n","        Score used is the accuracy of the model. (true positive + true negative rate)\n","        \"\"\"\n","        predictions = self.predict_tf(X_, w)\n","        accurate = tf.reduce_sum(tf.where(y == predictions, 1., 0.))\n","        n = tf.size(y)\n","        accuracy = accurate / n\n","        return accuracy\n","\n","    def predict_proba(self, X_):\n","        return self.predict_proba_tf(X_, self.w)\n","\n","    @tf.function(\n","        input_signature=[\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","        ]\n","    )\n","    def predict_proba_tf(self, X_, w):\n","        \"\"\"\n","        Returns probability p of class 1\n","        If p >= 0.5, then the predicted class is class 1 otherwise it's class 2.\n","        \"\"\"\n","        xw = X_ @ w\n","        p = logistic_sigmoid(xw)\n","        return p\n","\n","    def predict(self, X_):\n","        return self.predict_tf(X_, self.w)\n","\n","    @tf.function(\n","        input_signature=[\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","        ]\n","    )\n","    def predict_tf(self, X_, w):\n","        \"\"\"\n","        Prediction is a dot product... X_ @ w\n","        Predicted values follow the same convention used to create the y vector:\n","        1 = Class 1\n","        0 = Class 2\n","        \"\"\"\n","        xw = X_ @ w\n","        predictions = tf.where(xw >= 0, 1, 0)\n","        return predictions\n","\n","    @tf.function(\n","        input_signature=[\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=(), dtype=tf.float64),\n","        ]\n","    )\n","    def gradient(self, X_, y, w, alpha):\n","        \"\"\"\n","        First-derivative or Gradient of log-likelihood (w)\n","\n","        y denote the vector of yi values (yi = 1 for class 1 and yi = 0 for class 2)\n","        p vector of fitted probabilities p(xi; w)\n","\n","        Gradient = X.T * (y - p) - alpha * w\n","        \"\"\"\n","        xw = X_ @ w\n","        # vector of fitted probabilities p(xi; w)\n","        p = logistic_sigmoid(xw)\n","        # gradient vector\n","        gradient = X_.T @ (y - p) - alpha * w\n","        return gradient, p\n","\n","    @tf.function(\n","        input_signature=[\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=None, dtype=tf.float64),\n","            tf.TensorSpec(shape=(), dtype=tf.float64),\n","        ]\n","    )\n","    def hessian(self, X_, p, alpha):\n","        \"\"\"\n","        Second-derivative or Hessian matrix of log-likelihood(w).\n","\n","        Hessian = X.T @ R @ X + alpha * I\n","        \"\"\"\n","        # n: # of data points\n","        # f: # of features + 1\n","        x_shape = tf.shape(X_)\n","        n, f = x_shape[0], x_shape[1]\n","        # R is a N×N diagonal matrix of weights with ith diagonal element sigmoid(xi; w)(1 − sigmoid(xi; w))\n","        # The derivative of the sigmoid is sigmoid * (1 - sigmoid)\n","        sigmoid_deriv = p * (1 - p)\n","        R = tf.linalg.set_diag(tf.zeros([n, n], dtype=tf.float64), sigmoid_deriv)\n","        # X_.T @ R @ X_ shape is (f, f)\n","        H = -X_.T @ R @ X_ - alpha * tf.eye(f)\n","        return H\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sMTgjEDMJc88"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"OUEcgn7ouFmA"},"source":["lrc = LogisticRegressionClassifierTF(tol=1e-6, max_iter=500, learning_rate=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XQ-g4sGQwT6"},"source":["alphas = np.arange(0, 20, 1, dtype=np.float64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%time lrc.fit(xtr_, ytrb, alphas=alphas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiIOnFa8scix","executionInfo":{"status":"ok","timestamp":1641084471315,"user_tz":180,"elapsed":8847,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"5798ccb2-cbef-4847-a6b4-3e5a6ee7ceff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 14.4 s, sys: 441 ms, total: 14.9 s\n","Wall time: 8.72 s\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"id":"om6W2gQYNnz9","executionInfo":{"status":"ok","timestamp":1641084556873,"user_tz":180,"elapsed":309,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"25885582-a7ca-47fd-a350-78934c99b589"},"source":["plot_alpha_scores(alphas, lrc.alpha_scores.numpy())"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"d701edb5-1638-468b-9dd1-24fb34b5c1bc\" class=\"plotly-graph-div\" style=\"height:500px; width:500px;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"d701edb5-1638-468b-9dd1-24fb34b5c1bc\")) {\n","                    Plotly.newPlot(\n","                        'd701edb5-1638-468b-9dd1-24fb34b5c1bc',\n","                        [{\"mode\": \"lines\", \"name\": \"Alpha Scores\", \"type\": \"scatter\", \"x\": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0], \"y\": [0.8530000000000001, 0.8770000000000001, 0.875, 0.873, 0.8720000000000001, 0.8720000000000001, 0.8710000000000001, 0.8700000000000001, 0.869, 0.867, 0.867, 0.8630000000000001, 0.8620000000000001, 0.86, 0.859, 0.86, 0.857, 0.8560000000000001, 0.8550000000000001, 0.8550000000000001]}, {\"mode\": \"markers\", \"name\": \"Best Alpha\", \"type\": \"scatter\", \"x\": [1.0], \"y\": [0.8770000000000001]}],\n","                        {\"autosize\": true, \"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Alpha Scores\"}, \"width\": 500, \"xaxis\": {\"title\": {\"text\": \"Alpha\"}}, \"yaxis\": {\"title\": {\"text\": \"Score\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('d701edb5-1638-468b-9dd1-24fb34b5c1bc');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FekR7v4Juzsp","executionInfo":{"status":"ok","timestamp":1641084551337,"user_tz":180,"elapsed":354,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"f69a6343-30aa-44f4-c5a9-842088fea0d5"},"source":["lrc.alpha.numpy()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.])"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"2x5rCql98X8r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641084552664,"user_tz":180,"elapsed":280,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"ba1321cc-a648-41f8-cd14-238088a49731"},"source":["lrc.score(xte_, yteb).numpy()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9090909090909091"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"6q9mQhT_D_Lj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640907602633,"user_tz":180,"elapsed":386,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"fa3d0227-b6df-4858-da08-108e84849d99"},"source":["lrc.predict_proba(xte_).numpy(), yteb, yte, lrc.w"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0.1082648 , 0.06054096, 0.5913902 , 0.06331777, 0.15059279,\n","        0.44515334, 0.90891174, 0.89695178, 0.93672377, 0.06562928,\n","        0.52674758, 0.00805518, 0.61544615, 0.24889922, 0.13934653,\n","        0.09331497, 0.10788664, 0.91536926, 0.89616293, 0.19206788,\n","        0.1714575 , 0.15241934, 0.86452804, 0.10124173, 0.48193289,\n","        0.31092134, 0.93900133, 0.9220255 , 0.73984795, 0.41429229,\n","        0.26368699, 0.65141384, 0.08352205, 0.67039227, 0.08296025,\n","        0.03331867, 0.73363472, 0.05103853, 0.49635781, 0.98890182,\n","        0.03049984, 0.5676605 , 0.91905741, 0.17436481, 0.07005026,\n","        0.76963967, 0.2154854 , 0.55858888, 0.06634599, 0.89633215,\n","        0.48406254, 0.00926959, 0.47770605, 0.57905203, 0.31815713,\n","        0.35217281, 0.95525607, 0.61309419, 0.8006296 , 0.50414201,\n","        0.53501233, 0.20793392, 0.03972402, 0.02601745, 0.26525062,\n","        0.06591946, 0.82025277, 0.93247321, 0.87355866, 0.14064811,\n","        0.9752388 , 0.12586524, 0.06018296, 0.70551954, 0.06411423,\n","        0.69379183, 0.26627918, 0.75165032, 0.37852019, 0.66855895,\n","        0.61121036, 0.23822424, 0.02503264, 0.71530772, 0.30419078,\n","        0.96486081, 0.05961342, 0.04540727, 0.62449216, 0.1181823 ,\n","        0.60538895, 0.52793052, 0.20681574, 0.48683589, 0.09065243,\n","        0.12500149, 0.16727712, 0.71860571, 0.5067104 , 0.30924548,\n","        0.01587534, 0.28109593, 0.19005694, 0.07569892, 0.68995915,\n","        0.14554129, 0.92953787, 0.61841565, 0.55815511, 0.14956656]),\n"," array([0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n","        1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n","        0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n","        1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n","        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n","       dtype=int8),\n"," array([6, 6, 5, 6, 6, 6, 5, 5, 5, 6, 5, 6, 5, 5, 6, 6, 6, 5, 5, 6, 6, 6,\n","        5, 6, 6, 6, 5, 5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6,\n","        6, 5, 6, 5, 6, 5, 5, 6, 6, 5, 5, 6, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6,\n","        5, 5, 5, 5, 5, 5, 6, 5, 6, 5, 6, 5, 6, 5, 5, 5, 6, 5, 6, 5, 6, 6,\n","        5, 6, 5, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 6, 6]),\n"," <tf.Tensor: shape=(65,), dtype=float64, numpy=\n"," array([ 0.01130177, -0.23485547,  0.26653986,  1.73320345,  0.43726756,\n","         1.4965975 ,  3.70891945,  0.70852227,  0.21007819,  1.11344707,\n","         0.68761073,  2.30243386, -0.13021764,  1.24062873,  2.90063815,\n","         0.26317003, -0.52530214,  0.12668937,  1.33647107,  0.40909247,\n","        -0.96219088,  0.69216695, -0.40859056, -0.58265518, -0.37373447,\n","         0.62953989,  0.80041937, -0.0977952 ,  1.22825361,  1.52141562,\n","         0.22455483, -0.76689884,  0.13742385,  0.65621423, -0.607013  ,\n","        -1.93976029, -1.14482723, -0.16207978, -0.94911409, -0.25417547,\n","        -0.62016085, -0.3132868 , -0.37515363, -4.83634298, -2.44353915,\n","         0.04544619,  0.2193081 , -0.8819731 , -0.34007896,  0.17921418,\n","        -1.13436997, -1.59703238, -1.34440356,  1.5155515 , -0.99258535,\n","        -2.15451345, -0.12238134, -0.50324218, -0.70960835,  2.68508931,\n","         1.29977134, -1.13151503, -2.18725259, -0.51518969, -0.23813319])>)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"pdbzpVaZUfJE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627371212012,"user_tz":180,"elapsed":4867,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"c97ae653-98ba-4a30-d448-7e72547432ec"},"source":["%timeit lrc.predict(xte_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The slowest run took 11.75 times longer than the fastest. This could mean that an intermediate result is being cached.\n","1000 loops, best of 5: 686 µs per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dGGnSSVRl5jL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627371215900,"user_tz":180,"elapsed":3905,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"a8082fc0-584e-4545-8a70-d712f2ee41e2"},"source":["%timeit lrc.predict_proba(xte_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The slowest run took 14.33 times longer than the fastest. This could mean that an intermediate result is being cached.\n","1000 loops, best of 5: 601 µs per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LvvfpBBRGlMA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1YbwUOLq7jrc"},"source":["# Data pipeline with Datasets"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iaz72hNM7jC9","executionInfo":{"status":"ok","timestamp":1627373972433,"user_tz":180,"elapsed":1747,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"9bd78f4c-7e3e-4e86-9fbc-2d4a6556ed2e"},"source":["record_defaults = [0] * 64  # Only provide defaults for the selected columns\n","dataset = tf.data.experimental.CsvDataset(\"testData.csv\", record_defaults, header=False)\n","dataset = dataset.map(lambda *items: tf.stack(items))\n","dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<MapDataset shapes: (64,), types: tf.int32>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIgNE7tY--px","executionInfo":{"status":"ok","timestamp":1627373987274,"user_tz":180,"elapsed":414,"user":{"displayName":"Abner Correa Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZyXSLZZb4bf5e_THXAx4gDzqANn_BLalMJwcz9Q=s64","userId":"00785570743688316609"}},"outputId":"7647a310-fa4d-4b61-9dd1-eae7939cb342"},"source":["for line in dataset.take(1):\n","  print(line.numpy())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 0  0  0  1 13 10  0  0  0  8  0 10  2  5  0  5  5  2  2 14  0  5  0  0\n","  4  0  8  0  7 16  6  0  0  0 11 15  7  5  5  4  0  0  0  8  0  0 11  0\n","  0  5 16 12  0  9 16  0  0  0  4  0 14  0 15  0]\n"],"name":"stdout"}]}]}